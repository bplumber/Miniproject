# -*- coding: utf-8 -*-
"""InternetToPeer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kCvQ15N2dIv5glNBCLkLFW_6KvNY504p
"""

from googlesearch import search
from bs4 import BeautifulSoup
import requests
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def plagiarism_check(qry: str):
    user_notes = [qry]
    user_files = ['Student File']
    x_searches = []
    for x in search(query=qry, num=10, stop=10, pause=2.0):
        x_searches.append(x)

    for x in range(0, len(x_searches) - 1):
        url = x_searches[x]
        response = requests.get(url)

        soup = BeautifulSoup(response.text, 'html.parser')
        all_p = soup.find_all('p')
        all = ""
        for i in all_p:
          all += str(i.text)
        user_notes.append(all)
        user_files.append(url)

    def vectorize(Text): return TfidfVectorizer().fit_transform(Text).toarray()
    def similarity(doc1, doc2): return cosine_similarity([doc1, doc2])

    vectors = vectorize(user_notes)

    s_vectors = list(zip(user_files, vectors))
    plagiarism_results = set()
    student_a = s_vectors[0][0]
    text_vector_a = s_vectors[0][1]
  
    new_vectors = s_vectors.copy()
    current_index = new_vectors.index((student_a, text_vector_a))
    del new_vectors[current_index]
    for student_b, text_vector_b in new_vectors:
        sim_score = similarity(text_vector_a, text_vector_b)[0][1]
        student_pair = sorted((student_a, student_b))
        score = (student_pair[0], student_pair[1], sim_score)
        plagiarism_results.add(score)
    print(plagiarism_results)

def main():
    query = open('paraphrased.txt', encoding='utf-8').read()
    link = plagiarism_check(query)

if __name__ == '__main__':
    main()